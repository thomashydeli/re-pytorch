{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "# print(torch.__version__)\n",
    "# print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from modularized.engine import vggTrainingInfer, build_engine\n",
    "from modularized.data_processes import get_data, create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "# example image:\n",
    "np.asarray(Image.open('data/pizza_steak_sushi/test/pizza/194643.jpg')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, test_dir=get_data(\n",
    "    data_path='data/pizza_steak_sushi',\n",
    "    data_url='https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip',\n",
    "    unzip=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto creation of transformations\n",
    "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "auto_transforms=weights.transforms()\n",
    "\n",
    "# automatic transformations\n",
    "train_dataloader, test_dataloader, class_names, class_dict = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    img_size=(\n",
    "        auto_transforms.crop_size[0], auto_transforms.crop_size[0]\n",
    "    ),\n",
    "    transformations=auto_transforms,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torchvision.models.efficientnet_b0(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a summary of our model with torchinfo.summary()\n",
    "summary(\n",
    "    model, \n",
    "    input_size=(1,3,224,224),\n",
    "    col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "    col_width=20,\n",
    "    row_settings=['var_names']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the base model and chaging the output layer to suit the needs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "# Update the classifier head of our model to suit the problem\n",
    "model.classifier=nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(\n",
    "        in_features=1280,\n",
    "        out_features=len(class_names)\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up loss function and optimizer\n",
    "loss_fn=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(\n",
    "  model.parameters(),\n",
    "  lr=5e-4\n",
    ")\n",
    "\n",
    "# create engine and train\n",
    "print('performing training of the model')\n",
    "model, results=build_engine(\n",
    "  model=model,\n",
    "  loss_fn=loss_fn,\n",
    "  optimizer=optimizer,\n",
    "  train_dataloader=train_dataloader,\n",
    "  test_dataloader=test_dataloader,\n",
    "  epochs=20,\n",
    "  device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curves:\n",
    "fig=go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(10),\n",
    "        y=results['train_loss'],\n",
    "        name='train_loss'\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(10),\n",
    "        y=results['eval_loss'],\n",
    "        name='test_loss'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(dict(\n",
    "    title='Loss Plots',\n",
    "    width=500,\n",
    "    height=500\n",
    "))\n",
    "fig.show()\n",
    "\n",
    "# plot loss curves:\n",
    "fig=go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(10),\n",
    "        y=results['train_metric'],\n",
    "        name='train_acc'\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.arange(10),\n",
    "        y=results['eval_metric'],\n",
    "        name='test_acc'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(dict(\n",
    "    title='Accuracy Plots',\n",
    "    width=500,\n",
    "    height=500\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "def pred_and_plot_image(\n",
    "    model,\n",
    "    image_path,\n",
    "    class_names,\n",
    "    image_size,\n",
    "    transform=None,\n",
    "    device='cpu',\n",
    "):\n",
    "    img=Image.open(image_path)\n",
    "\n",
    "    if transform is None:\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        transformed_image=transform(img).unsqueeze(dim=0)\n",
    "        target_image_pred=model(transformed_image.to(device))\n",
    "    \n",
    "    target_image_pred_probs=torch.softmax(target_image_pred, dim=1)\n",
    "    target_image_pred_label=torch.argmax(target_image_pred_probs, dim=1).item()\n",
    "    target_image_pred_probs=target_image_pred_probs.numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs[0][target_image_pred_label]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_plot_image(\n",
    "    model,\n",
    "    image_path='data/pizza_steak_sushi/eval/04-pizza-dad.jpeg',\n",
    "    class_names=class_names,\n",
    "    image_size=(224,224),\n",
    "    transform=auto_transforms,\n",
    "    device='cpu',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
